{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "ResNet18.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGneF6wedinh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "293f24c8-3ff1-43f5-cac5-b8353c78db96"
      },
      "source": [
        "import sys\n",
        "sys.path[0] = '/tensorflow-2.1.0/python3.6'\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1xKcH__dinq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Sequential, losses, optimizers, datasets\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTHHiW0Ddinu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6863adda-22fd-429c-e9f5-1a22959c102f"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2GOo6Apdinz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "adcec94c-c38f-4263-e67f-0912c9f66001"
      },
      "source": [
        "(x, y), (x_test, y_test) = datasets.cifar100.load_data()\n",
        "print(x.shape,y.shape,x_test.shape,y_test.shape)\n",
        "print(x.dtype,y.dtype)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
            "uint8 int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTPgQhmrdin2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(x, y):\n",
        "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
        "    y = tf.cast(to_categorical(tf.squeeze(tf.cast(y, dtype=tf.int32), axis=1), num_classes=100), dtype=tf.int32)\n",
        "    return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAbJ7PgVdin5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(layers.Layer):\n",
        "    \n",
        "    def __init__(self, filter_num, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = layers.Conv2D(filter_num, (3, 3), strides=stride, padding='same')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.relu = layers.Activation('relu')\n",
        "        self.drop1 = layers.Dropout(0.5)\n",
        "        self.conv2 = layers.Conv2D(filter_num, (3, 3), strides=1, padding='same')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "        self.drop2 = layers.Dropout(0.5)\n",
        "        if stride != 1:\n",
        "            self.downsample = layers.Conv2D(filter_num, (1, 1), strides=(stride, stride), padding='valid')\n",
        "        else:\n",
        "            self.downsample = lambda x:x\n",
        "    \n",
        "    def call(self, inputs, training=None):\n",
        "        out = self.conv1(inputs)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.drop1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.drop2(out)\n",
        "\n",
        "        identity = self.downsample(inputs)\n",
        "        output = layers.add([identity, out])\n",
        "        output = tf.nn.relu(output)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAm4qiA8din6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(keras.Model):\n",
        "\n",
        "    def __init__(self, layer_dims, num_classes=100):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.stem = Sequential([layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same'),\n",
        "                                layers.BatchNormalization(),\n",
        "                                layers.Activation('relu'),\n",
        "                                layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='same')\n",
        "                               ])\n",
        "        self.block1 = self.build_resblock(64, layer_dims[0])\n",
        "        self.block2 = self.build_resblock(128, layer_dims[1], stride=2)\n",
        "        self.block3 = self.build_resblock(256, layer_dims[2], stride=2)\n",
        "        self.block4 = self.build_resblock(512, layer_dims[3], stride=2)\n",
        "        self.avgpool = layers.GlobalAveragePooling2D()\n",
        "        self.fc = layers.Dense(num_classes, activation=tf.nn.softmax)\n",
        "    \n",
        "    def call(self, inputs, training=None):\n",
        "        x = self.stem(inputs)\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)       \n",
        "        x = self.block3(x)     \n",
        "        x = self.block4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "      \n",
        "    def build_resblock(self, filter_num, blocks, stride=1):\n",
        "      res_blocks = Sequential()\n",
        "      res_blocks.add(BasicBlock(filter_num, stride))\n",
        "      for _ in range(1, blocks):\n",
        "          res_blocks.add(BasicBlock(filter_num, stride=1))\n",
        "      return res_blocks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RN82lU8din8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(x, y, x_test, y_test):\n",
        "    epochs = 100\n",
        "    model = ResNet([2, 2, 2, 2])\n",
        "    model.build(input_shape=(None, 32, 32, 3))\n",
        "    model.summary()\n",
        "    save_best = keras.callbacks.ModelCheckpoint('/drive/My Drive/Github/CNN/ResNet_best_model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, min_delta=0, patience=100, mode='auto')\n",
        "    callbacks_list = [early_stop, save_best]\n",
        "    model.compile(optimizer=optimizers.Adam(lr=1e-2),\n",
        "                 loss=losses.categorical_crossentropy,\n",
        "                 metrics=['accuracy'])\n",
        "    x, y = preprocess(x, y)\n",
        "    x_test, y_test = preprocess(x_test, y_test)\n",
        "    history = model.fit(x=x, y=y, epochs=epochs, batch_size=512, validation_data=(x_test, y_test), verbose=1, callbacks=callbacks_list)\n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESxyjSOwdin-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c81e4cb1-2e81-46f8-b30f-5eb5739e423d"
      },
      "source": [
        "main(x, y, x_test, y_test)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"res_net_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_184 (Sequential)  multiple                  2048      \n",
            "_________________________________________________________________\n",
            "sequential_185 (Sequential)  multiple                  148736    \n",
            "_________________________________________________________________\n",
            "sequential_186 (Sequential)  multiple                  526976    \n",
            "_________________________________________________________________\n",
            "sequential_187 (Sequential)  multiple                  2102528   \n",
            "_________________________________________________________________\n",
            "sequential_188 (Sequential)  multiple                  8399360   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_32  multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             multiple                  51300     \n",
            "=================================================================\n",
            "Total params: 11,230,948\n",
            "Trainable params: 11,223,140\n",
            "Non-trainable params: 7,808\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 4.9070 - accuracy: 0.0132\n",
            "Epoch 00001: val_loss improved from inf to 53.09337, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 55s 1ms/sample - loss: 4.9046 - accuracy: 0.0133 - val_loss: 53.0934 - val_accuracy: 0.0118\n",
            "Epoch 2/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 4.3057 - accuracy: 0.0434\n",
            "Epoch 00002: val_loss improved from 53.09337 to 4.58589, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 4.3043 - accuracy: 0.0435 - val_loss: 4.5859 - val_accuracy: 0.0198\n",
            "Epoch 3/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 3.8892 - accuracy: 0.0940\n",
            "Epoch 00003: val_loss improved from 4.58589 to 3.97933, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 52s 1ms/sample - loss: 3.8885 - accuracy: 0.0940 - val_loss: 3.9793 - val_accuracy: 0.0924\n",
            "Epoch 4/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 3.6210 - accuracy: 0.1383\n",
            "Epoch 00004: val_loss improved from 3.97933 to 3.81074, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 3.6209 - accuracy: 0.1386 - val_loss: 3.8107 - val_accuracy: 0.1084\n",
            "Epoch 5/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 3.4402 - accuracy: 0.1696\n",
            "Epoch 00005: val_loss improved from 3.81074 to 3.64215, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 52s 1ms/sample - loss: 3.4396 - accuracy: 0.1698 - val_loss: 3.6421 - val_accuracy: 0.1421\n",
            "Epoch 6/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 3.2940 - accuracy: 0.1964\n",
            "Epoch 00006: val_loss improved from 3.64215 to 3.54918, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 52s 1ms/sample - loss: 3.2939 - accuracy: 0.1965 - val_loss: 3.5492 - val_accuracy: 0.1576\n",
            "Epoch 7/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 3.1614 - accuracy: 0.2225\n",
            "Epoch 00007: val_loss did not improve from 3.54918\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 3.1623 - accuracy: 0.2224 - val_loss: 3.7402 - val_accuracy: 0.1419\n",
            "Epoch 8/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 3.0260 - accuracy: 0.2472\n",
            "Epoch 00008: val_loss improved from 3.54918 to 3.39532, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 3.0250 - accuracy: 0.2473 - val_loss: 3.3953 - val_accuracy: 0.1917\n",
            "Epoch 9/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 2.8855 - accuracy: 0.2759\n",
            "Epoch 00009: val_loss improved from 3.39532 to 3.04284, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 52s 1ms/sample - loss: 2.8858 - accuracy: 0.2760 - val_loss: 3.0428 - val_accuracy: 0.2486\n",
            "Epoch 10/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 2.7588 - accuracy: 0.2981\n",
            "Epoch 00010: val_loss improved from 3.04284 to 2.87162, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 52s 1ms/sample - loss: 2.7580 - accuracy: 0.2984 - val_loss: 2.8716 - val_accuracy: 0.2811\n",
            "Epoch 11/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 2.6209 - accuracy: 0.3285\n",
            "Epoch 00011: val_loss did not improve from 2.87162\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 2.6204 - accuracy: 0.3286 - val_loss: 3.0010 - val_accuracy: 0.2575\n",
            "Epoch 12/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 2.5018 - accuracy: 0.3496\n",
            "Epoch 00012: val_loss did not improve from 2.87162\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 2.5022 - accuracy: 0.3496 - val_loss: 3.3054 - val_accuracy: 0.2269\n",
            "Epoch 13/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 2.4010 - accuracy: 0.3683\n",
            "Epoch 00013: val_loss improved from 2.87162 to 2.84080, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 52s 1ms/sample - loss: 2.4014 - accuracy: 0.3685 - val_loss: 2.8408 - val_accuracy: 0.3093\n",
            "Epoch 14/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.3893\n",
            "Epoch 00014: val_loss improved from 2.84080 to 2.72795, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 52s 1ms/sample - loss: 2.3023 - accuracy: 0.3894 - val_loss: 2.7280 - val_accuracy: 0.3222\n",
            "Epoch 15/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 2.2182 - accuracy: 0.4083\n",
            "Epoch 00015: val_loss did not improve from 2.72795\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 2.2185 - accuracy: 0.4083 - val_loss: 3.9266 - val_accuracy: 0.2060\n",
            "Epoch 16/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 2.1206 - accuracy: 0.4293\n",
            "Epoch 00016: val_loss improved from 2.72795 to 2.71358, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 52s 1ms/sample - loss: 2.1214 - accuracy: 0.4291 - val_loss: 2.7136 - val_accuracy: 0.3433\n",
            "Epoch 17/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 2.0563 - accuracy: 0.4418\n",
            "Epoch 00017: val_loss did not improve from 2.71358\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 2.0571 - accuracy: 0.4416 - val_loss: 3.0477 - val_accuracy: 0.2823\n",
            "Epoch 18/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.9897 - accuracy: 0.4608\n",
            "Epoch 00018: val_loss did not improve from 2.71358\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.9911 - accuracy: 0.4603 - val_loss: 3.3135 - val_accuracy: 0.2672\n",
            "Epoch 19/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.9156 - accuracy: 0.4737\n",
            "Epoch 00019: val_loss improved from 2.71358 to 2.39327, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 52s 1ms/sample - loss: 1.9163 - accuracy: 0.4735 - val_loss: 2.3933 - val_accuracy: 0.4008\n",
            "Epoch 20/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.8647 - accuracy: 0.4879\n",
            "Epoch 00020: val_loss did not improve from 2.39327\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.8649 - accuracy: 0.4877 - val_loss: 2.8653 - val_accuracy: 0.3129\n",
            "Epoch 21/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.8212 - accuracy: 0.4961\n",
            "Epoch 00021: val_loss improved from 2.39327 to 2.29926, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 52s 1ms/sample - loss: 1.8210 - accuracy: 0.4959 - val_loss: 2.2993 - val_accuracy: 0.4075\n",
            "Epoch 22/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.7666 - accuracy: 0.5078\n",
            "Epoch 00022: val_loss did not improve from 2.29926\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.7666 - accuracy: 0.5078 - val_loss: 3.1745 - val_accuracy: 0.3092\n",
            "Epoch 23/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.7107 - accuracy: 0.5222\n",
            "Epoch 00023: val_loss did not improve from 2.29926\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.7110 - accuracy: 0.5223 - val_loss: 3.5173 - val_accuracy: 0.2730\n",
            "Epoch 24/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.6816 - accuracy: 0.5257\n",
            "Epoch 00024: val_loss did not improve from 2.29926\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.6820 - accuracy: 0.5255 - val_loss: 4.4819 - val_accuracy: 0.2277\n",
            "Epoch 25/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.6296 - accuracy: 0.5391\n",
            "Epoch 00025: val_loss improved from 2.29926 to 2.14427, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 52s 1ms/sample - loss: 1.6288 - accuracy: 0.5393 - val_loss: 2.1443 - val_accuracy: 0.4405\n",
            "Epoch 26/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.5945 - accuracy: 0.5481\n",
            "Epoch 00026: val_loss did not improve from 2.14427\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.5950 - accuracy: 0.5481 - val_loss: 2.1991 - val_accuracy: 0.4343\n",
            "Epoch 27/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.5466 - accuracy: 0.5583\n",
            "Epoch 00027: val_loss did not improve from 2.14427\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.5468 - accuracy: 0.5584 - val_loss: 2.1478 - val_accuracy: 0.4384\n",
            "Epoch 28/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.5103 - accuracy: 0.5714\n",
            "Epoch 00028: val_loss did not improve from 2.14427\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.5099 - accuracy: 0.5714 - val_loss: 2.2336 - val_accuracy: 0.4276\n",
            "Epoch 29/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.4703 - accuracy: 0.5775\n",
            "Epoch 00029: val_loss did not improve from 2.14427\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.4699 - accuracy: 0.5776 - val_loss: 3.5668 - val_accuracy: 0.2858\n",
            "Epoch 30/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.4439 - accuracy: 0.5834\n",
            "Epoch 00030: val_loss did not improve from 2.14427\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.4439 - accuracy: 0.5836 - val_loss: 2.6884 - val_accuracy: 0.3689\n",
            "Epoch 31/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.4178 - accuracy: 0.5897\n",
            "Epoch 00031: val_loss did not improve from 2.14427\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.4176 - accuracy: 0.5898 - val_loss: 3.1021 - val_accuracy: 0.3222\n",
            "Epoch 32/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.3792 - accuracy: 0.5997\n",
            "Epoch 00032: val_loss did not improve from 2.14427\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.3788 - accuracy: 0.5998 - val_loss: 3.2190 - val_accuracy: 0.3153\n",
            "Epoch 33/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.3575 - accuracy: 0.6054\n",
            "Epoch 00033: val_loss did not improve from 2.14427\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.3575 - accuracy: 0.6057 - val_loss: 2.5422 - val_accuracy: 0.3892\n",
            "Epoch 34/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.3274 - accuracy: 0.6096\n",
            "Epoch 00034: val_loss improved from 2.14427 to 2.14302, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 52s 1ms/sample - loss: 1.3281 - accuracy: 0.6095 - val_loss: 2.1430 - val_accuracy: 0.4532\n",
            "Epoch 35/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.2830 - accuracy: 0.6232\n",
            "Epoch 00035: val_loss improved from 2.14302 to 2.12557, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 52s 1ms/sample - loss: 1.2842 - accuracy: 0.6229 - val_loss: 2.1256 - val_accuracy: 0.4635\n",
            "Epoch 36/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.2686 - accuracy: 0.6269\n",
            "Epoch 00036: val_loss did not improve from 2.12557\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.2696 - accuracy: 0.6265 - val_loss: 2.1402 - val_accuracy: 0.4621\n",
            "Epoch 37/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.2368 - accuracy: 0.6360\n",
            "Epoch 00037: val_loss did not improve from 2.12557\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.2374 - accuracy: 0.6357 - val_loss: 2.1560 - val_accuracy: 0.4629\n",
            "Epoch 38/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.2193 - accuracy: 0.6412\n",
            "Epoch 00038: val_loss did not improve from 2.12557\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.2193 - accuracy: 0.6412 - val_loss: 2.6052 - val_accuracy: 0.4108\n",
            "Epoch 39/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.2017 - accuracy: 0.6447\n",
            "Epoch 00039: val_loss did not improve from 2.12557\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.2020 - accuracy: 0.6446 - val_loss: 2.3589 - val_accuracy: 0.4322\n",
            "Epoch 40/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.1784 - accuracy: 0.6503\n",
            "Epoch 00040: val_loss did not improve from 2.12557\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.1787 - accuracy: 0.6502 - val_loss: 2.4439 - val_accuracy: 0.4253\n",
            "Epoch 41/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.1465 - accuracy: 0.6576\n",
            "Epoch 00041: val_loss improved from 2.12557 to 2.05128, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.1466 - accuracy: 0.6575 - val_loss: 2.0513 - val_accuracy: 0.4825\n",
            "Epoch 42/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.1330 - accuracy: 0.6586\n",
            "Epoch 00042: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.1333 - accuracy: 0.6586 - val_loss: 2.5423 - val_accuracy: 0.4118\n",
            "Epoch 43/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.1072 - accuracy: 0.6680\n",
            "Epoch 00043: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.1073 - accuracy: 0.6679 - val_loss: 2.0532 - val_accuracy: 0.4829\n",
            "Epoch 44/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.1011 - accuracy: 0.6688\n",
            "Epoch 00044: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.1006 - accuracy: 0.6690 - val_loss: 2.0706 - val_accuracy: 0.4762\n",
            "Epoch 45/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.0787 - accuracy: 0.6718\n",
            "Epoch 00045: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 50s 1ms/sample - loss: 1.0802 - accuracy: 0.6716 - val_loss: 2.2781 - val_accuracy: 0.4375\n",
            "Epoch 46/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.0522 - accuracy: 0.6814\n",
            "Epoch 00046: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 50s 1ms/sample - loss: 1.0523 - accuracy: 0.6814 - val_loss: 2.9810 - val_accuracy: 0.3728\n",
            "Epoch 47/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.0313 - accuracy: 0.6878\n",
            "Epoch 00047: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 50s 1ms/sample - loss: 1.0320 - accuracy: 0.6876 - val_loss: 2.1410 - val_accuracy: 0.4780\n",
            "Epoch 48/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.0201 - accuracy: 0.6901\n",
            "Epoch 00048: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.0196 - accuracy: 0.6901 - val_loss: 3.5216 - val_accuracy: 0.3281\n",
            "Epoch 49/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 0.9928 - accuracy: 0.6952\n",
            "Epoch 00049: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 0.9931 - accuracy: 0.6951 - val_loss: 2.5075 - val_accuracy: 0.4344\n",
            "Epoch 50/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 0.9719 - accuracy: 0.7032\n",
            "Epoch 00050: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 0.9715 - accuracy: 0.7032 - val_loss: 2.5041 - val_accuracy: 0.4419\n",
            "Epoch 51/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 0.9527 - accuracy: 0.7053\n",
            "Epoch 00051: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 0.9529 - accuracy: 0.7052 - val_loss: 3.1147 - val_accuracy: 0.3655\n",
            "Epoch 52/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 0.9562 - accuracy: 0.7074\n",
            "Epoch 00052: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 50s 1ms/sample - loss: 0.9559 - accuracy: 0.7074 - val_loss: 2.2990 - val_accuracy: 0.4567\n",
            "Epoch 53/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 0.9251 - accuracy: 0.7145\n",
            "Epoch 00053: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 50s 1ms/sample - loss: 0.9260 - accuracy: 0.7141 - val_loss: 2.2577 - val_accuracy: 0.4633\n",
            "Epoch 54/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 0.9068 - accuracy: 0.7196\n",
            "Epoch 00054: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 0.9074 - accuracy: 0.7196 - val_loss: 2.1381 - val_accuracy: 0.4810\n",
            "Epoch 55/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 0.9109 - accuracy: 0.7161\n",
            "Epoch 00055: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 0.9110 - accuracy: 0.7161 - val_loss: 2.3104 - val_accuracy: 0.4609\n",
            "Epoch 56/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 0.9039 - accuracy: 0.7201\n",
            "Epoch 00056: val_loss did not improve from 2.05128\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 0.9042 - accuracy: 0.7202 - val_loss: 2.1013 - val_accuracy: 0.4910\n",
            "Epoch 57/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 0.8840 - accuracy: 0.7268\n",
            "Epoch 00057: val_loss improved from 2.05128 to 1.99505, saving model to /drive/My Drive/Github/CNN/ResNet_best_model.h5\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 0.8843 - accuracy: 0.7267 - val_loss: 1.9951 - val_accuracy: 0.5120\n",
            "Epoch 58/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 0.8636 - accuracy: 0.7316\n",
            "Epoch 00058: val_loss did not improve from 1.99505\n",
            "50000/50000 [==============================] - 50s 1ms/sample - loss: 0.8641 - accuracy: 0.7314 - val_loss: 3.4294 - val_accuracy: 0.3344\n",
            "Epoch 59/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 0.8440 - accuracy: 0.7376\n",
            "Epoch 00059: val_loss did not improve from 1.99505\n",
            "50000/50000 [==============================] - 50s 1ms/sample - loss: 0.8446 - accuracy: 0.7376 - val_loss: 2.4367 - val_accuracy: 0.4521\n",
            "Epoch 60/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 0.8401 - accuracy: 0.7380\n",
            "Epoch 00060: val_loss did not improve from 1.99505\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 0.8414 - accuracy: 0.7376 - val_loss: 3.7032 - val_accuracy: 0.3500\n",
            "Epoch 61/100\n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 0.8385 - accuracy: 0.7370\n",
            "Epoch 00061: val_loss did not improve from 1.99505\n",
            "50000/50000 [==============================] - 50s 1ms/sample - loss: 0.8396 - accuracy: 0.7366 - val_loss: 2.0806 - val_accuracy: 0.4960\n",
            "Epoch 62/100\n",
            "18944/50000 [==========>...................] - ETA: 29s - loss: 0.8115 - accuracy: 0.7435WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-423d6b56c91e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-137-c7c777f5bf0f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(x, y, x_test, y_test)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0BGg9gfdioA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}